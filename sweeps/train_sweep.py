import os
import yaml
import wandb
import mlflow
import mlflow.xgboost
import xgboost as xgb
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ğŸ“‚ Load MLflow configuration
CONFIG_PATH = os.path.join(os.path.dirname(__file__), "..", "config", "mlflow_config.yaml")

with open(CONFIG_PATH, "r") as file:
    mlflow_config = yaml.safe_load(file)  # Read YAML into a dictionary

# ğŸ› ï¸ Set up MLflow tracking
mlflow.set_tracking_uri(mlflow_config["mlflow"]["tracking_uri"])
mlflow.set_experiment(mlflow_config["mlflow"]["experiment_name"])

# ğŸ  W&B configuration
WANDB_PROJECT = "mlops_housing"

def train():
    """Train an XGBoost model with W&B and MLflow logging."""
    
    # ğŸš€ Initialize W&B
    wandb.init(project=WANDB_PROJECT, config={
        "n_estimators": 100,
        "learning_rate": 0.1,
        "max_depth": 6,
        "subsample": 0.8,
        "colsample_bytree": 0.8
    })

    # ğŸ“Œ Retrieve parameters from W&B
    config = wandb.config

    # ğŸ“‚ Load dataset
    df = pd.read_csv("data/processed/housing_cleaned.csv")
    
    # âŒ Remove unnecessary columns (like 'Unnamed: 0' if present)
    df = df.loc[:, ~df.columns.str.contains('Unnamed')]

    target_column = "median_house_value"
    y = df[target_column]
    X = df.drop(columns=[target_column])

    # âœ‚ï¸ Split into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # ğŸ” Ensure feature names are properly formatted
    X_train.columns = X_train.columns.astype(str)
    X_train.columns = X_train.columns.str.replace("[\[\]<>]", "", regex=True)
    X_test.columns = X_test.columns.astype(str)
    X_test.columns = X_test.columns.str.replace("[\[\]<>]", "", regex=True)

    print("âœ… Feature Names (X_train):", X_train.columns.tolist())  # Debug

    # ğŸ¯ Train XGBoost model
    model = xgb.XGBRegressor(
        n_estimators=config.n_estimators,
        learning_rate=config.learning_rate,
        max_depth=config.max_depth,
        subsample=config.subsample,
        colsample_bytree=config.colsample_bytree,
        objective="reg:squarederror",
        random_state=42
    )
    model.fit(X_train, y_train)

    # ğŸ” Make predictions
    y_pred = model.predict(X_test)

    # ğŸ“ Calculate evaluation metrics
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    # ğŸŸ¡ Log metrics in W&B
    wandb.log({"Final Test RMSE": rmse, "Final Test MAE": mae, "Final Test RÂ² Score": r2})

    # ğŸ”µ Log metrics & model in MLflow
    with mlflow.start_run():
        mlflow.log_params(dict(config))  # Log hyperparameters
        mlflow.log_metrics({"RMSE": rmse, "MAE": mae, "RÂ² Score": r2})  # Log metrics
        mlflow.xgboost.log_model(model, "xgb_model")  # Save model

    # ğŸ‰ Improved print statement
    print("\n" + "="*50)
    print(f"âœ… W&B + MLflow Logging Completed!")
    print(f"ğŸ“Š RMSE: {rmse:.2f}")
    print(f"ğŸ“ MAE: {mae:.2f}")
    print(f"ğŸ“ˆ RÂ² Score: {r2:.4f}")
    print("="*50 + "\n")

    # ğŸ¯ Finish W&B session
    wandb.finish()

